{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e04338f",
   "metadata": {},
   "source": [
    "# YOLOv5_alumnos - Deteccion de Objetos Personalizada\n",
    "**Asignatura:** Programacion con IA  \n",
    "**Proyecto:** SENTINEL HUD (Seguridad industrial con deteccion de EPIs)  \n",
    "**Alumno:** Diego Sanchez  \n",
    "**Fecha:** 14/02/2026\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e4350a",
   "metadata": {},
   "source": [
    "## 1. Definicion del problema\n",
    "Se plantea un sistema de deteccion de objetos para mejorar la seguridad en entornos industriales.  \n",
    "El problema concreto es detectar automaticamente incumplimientos de EPI y zonas/objetos de riesgo en imagenes de planta.\n",
    "\n",
    "Clases objetivo del detector:\n",
    "- `Casco`\n",
    "- `Chaleco`\n",
    "- `Persona_Sin_Equipo`\n",
    "- `Peligro`\n",
    "\n",
    "Uso esperado: monitorizacion automatica y alerta temprana para reducir supervision manual y riesgo operativo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a13281",
   "metadata": {},
   "source": [
    "## 2. Creacion / obtencion del dataset\n",
    "Se utilizo un dataset propio en formato YOLO (`images/` + `labels/`) con split train/val.\n",
    "\n",
    "Resumen del dataset final:\n",
    "- Imagenes train: **138**\n",
    "- Etiquetas train: **138**\n",
    "- Imagenes val: **38**\n",
    "- Etiquetas val: **38**\n",
    "- Clases: **4**\n",
    "\n",
    "Archivo de configuracion: `dataset_final/custom_data.yaml`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4df9ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estructura y YAML del dataset\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "yaml_path = Path('dataset_final/custom_data.yaml')\n",
    "print(yaml_path.read_text(encoding='utf-8'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab034b03",
   "metadata": {},
   "source": [
    "## 3. Proceso de entrenamiento del modelo (paso a paso)\n",
    "1. Se clono el repositorio oficial de YOLOv5 y se instalaron dependencias.\n",
    "2. Se configuro el dataset custom (`dataset_final/custom_data.yaml`) con 4 clases.\n",
    "3. Se aplico fine-tuning desde pesos preentrenados (`yolov5s.pt`).\n",
    "4. Se entreno con imagenes de 640 px y `batch=8` para equilibrar consumo de RAM y estabilidad.\n",
    "5. Se habilito `--cache` para reducir I/O de disco durante entrenamiento.\n",
    "6. Se guardaron automaticamente `best.pt` (mejor mAP@0.5 en validacion interna) y `last.pt`.\n",
    "\n",
    "Hardware verificado:\n",
    "- `nvidia-smi`: GPU fisica disponible (RTX 2070)\n",
    "- `torch.cuda.is_available()`: `False` (entorno con `torch 2.10.0+cpu`)\n",
    "\n",
    "Conclusiones de entorno:\n",
    "- El entrenamiento se ejecuto 100% en CPU.\n",
    "- Por esta limitacion se uso una corrida de 10 epocas para mantener tiempos razonables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954957c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "python yolov5/train.py \\\n",
    "  --img 640 \\\n",
    "  --batch 8 \\\n",
    "  --epochs 10 \\\n",
    "  --data dataset_final/custom_data.yaml \\\n",
    "  --weights yolov5s.pt \\\n",
    "  --cache \\\n",
    "  --project yolov5/runs_academic \\\n",
    "  --name actividad1_10e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167b5d78",
   "metadata": {},
   "source": [
    "## 4. Informe de resultados del modelo\n",
    "### 4.1 Datos objetivos (metricas)\n",
    "Fuente primaria de metricas globales por epoca: `yolov5/runs_academic/actividad1_10e/results.csv`\n",
    "\n",
    "Coherencia verificada entre entrenamiento y validacion:\n",
    "- Mejor epoca por `mAP@0.5`: **8**\n",
    "- Mejor epoca por `mAP@0.5:0.95`: **9**\n",
    "\n",
    "Metricas de la epoca 8 (seleccion de `best.pt` por mAP@0.5):\n",
    "- Precision: **0.251**\n",
    "- Recall: **0.395**\n",
    "- mAP@0.5: **0.322**\n",
    "- mAP@0.5:0.95: **0.111**\n",
    "\n",
    "Metricas de la ultima epoca (epoca 9):\n",
    "- Precision: **0.241**\n",
    "- Recall: **0.268**\n",
    "- mAP@0.5: **0.305**\n",
    "- mAP@0.5:0.95: **0.111**\n",
    "\n",
    "Control de reproducibilidad de validacion (`best.pt`):\n",
    "- `batch=16` (`yolov5/runs_academic/audit_val_bs16_log.txt`): all P=0.251, R=0.396, mAP50=0.322, mAP50-95=0.111.\n",
    "- `batch=32` (`yolov5/runs_academic/audit_val_bs32_log.txt`): all P=0.222, R=0.414, mAP50=0.283, mAP50-95=0.107.\n",
    "\n",
    "Interpretacion metodologica:\n",
    "- En este dataset pequeno (38 imagenes de validacion), la metrica presenta sensibilidad al tamano de lote en `val.py`.\n",
    "- Para consistencia academica, las metricas reportadas se anclan en `results.csv` y en la revalidacion `batch=16`, que coincide con la seleccion de `best.pt`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1313f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curvas y matriz de confusion generadas por YOLOv5\n",
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(filename='yolov5/runs_academic/actividad1_10e/results.png', width=900))\n",
    "display(Image(filename='yolov5/runs_academic/val_actividad1_bs16/confusion_matrix.png', width=650))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c936099f",
   "metadata": {},
   "source": [
    "### 4.2 Metricas por clase (validacion final coherente con best.pt)\n",
    "Fuente: `yolov5/runs_academic/audit_val_bs16_log.txt`\n",
    "\n",
    "- all: P=0.251, R=0.396, mAP50=0.322, mAP50-95=0.111\n",
    "- Casco: P=0.562, R=0.352, mAP50=0.395, mAP50-95=0.110\n",
    "- Chaleco: P=0.259, R=0.600, mAP50=0.452, mAP50-95=0.154\n",
    "- Persona_Sin_Equipo: P=0.0772, R=0.132, mAP50=0.102, mAP50-95=0.0385\n",
    "- Peligro: P=0.108, R=0.500, mAP50=0.337, mAP50-95=0.141\n",
    "\n",
    "### 4.3 Analisis tecnico critico\n",
    "Lectura profesional de mAP@0.5 vs mAP@0.5:0.95:\n",
    "- `mAP@0.5` confirma capacidad de deteccion con criterio IoU permisivo.\n",
    "- `mAP@0.5:0.95` penaliza la localizacion fina de caja (IoU altos), por eso cae a 0.111.\n",
    "- La brecha (0.322 vs 0.111) indica detector funcional, pero aun lejos de una precision espacial robusta.\n",
    "\n",
    "Convergencia, overfitting y underfitting:\n",
    "- `train/box_loss`: 0.0849 -> 0.0398 (**-53.2%**).\n",
    "- `val/box_loss`: 0.0333 -> 0.0166 (**-50.3%**).\n",
    "- `val/obj_loss`: 0.0180 -> 0.0078 (**-56.6%**).\n",
    "- No hay divergencia train-val sostenida, por lo que **no** hay evidencia fuerte de overfitting en 10 epocas.\n",
    "- Si hay evidencia de **underfitting parcial**: la localizacion fina sigue baja (mAP50-95=0.111) y la metrica por clase critica sigue debil.\n",
    "\n",
    "Diagnostico por clase y dataset:\n",
    "- `Persona_Sin_Equipo` es el cuello de botella real (mAP50=0.102, R=0.132).\n",
    "- El dataset esta casi balanceado por clase en train (32-36 instancias/clase), pero el volumen total es bajo (138 instancias train, 38 val).\n",
    "- En validacion, `Persona_Sin_Equipo` tiene solo 7 instancias, lo que eleva varianza estadistica y vuelve inestable la comparacion de modelos.\n",
    "\n",
    "Debilidades tecnicas objetivas de la entrega actual:\n",
    "- Validacion final sin set externo no visto (se usan muestras del split val en inferencia cualitativa).\n",
    "- Falta de analisis de sensibilidad experimental (seed, workers, batch, TTA) para robustez de conclusiones.\n",
    "- Entrenamiento corto para un diagnostico de convergencia completa (10 epocas con 3 de warmup).\n",
    "\n",
    "Mejoras realistas para subir a nivel 10:\n",
    "- Crear test set externo (20-40 imagenes) y reportar metricas separadas de val.\n",
    "- Aumentar datos de `Persona_Sin_Equipo` en escenarios dificiles (occlusion, escala, contraluz, poses).\n",
    "- Probar 50 epocas en CUDA con early stopping y comparar contra baseline 10 epocas.\n",
    "- Ajustar hiperparametros focalizados en localizacion (`scale`, `translate`, `iou_t`, `anchor_t`) con protocolo fijo de validacion.\n",
    "- Repetir validacion con semilla fija y `workers=0` para reducir variabilidad de medicion en CPU.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030b5dff",
   "metadata": {},
   "source": [
    "## 5. Inferencia del modelo\n",
    "Se ejecuto inferencia con `best.pt` para inspeccion cualitativa de predicciones.\n",
    "\n",
    "Comando de inferencia:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3392de88",
   "metadata": {},
   "outputs": [],
   "source": [
    "python yolov5/detect.py \\\n",
    "  --weights yolov5/runs_academic/actividad1_10e/weights/best.pt \\\n",
    "  --img 640 \\\n",
    "  --conf 0.10 \\\n",
    "  --source inference_samples_val \\\n",
    "  --project yolov5/runs_academic \\\n",
    "  --name inferencia_actividad1_val\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e67ba7a",
   "metadata": {},
   "source": [
    "Ejemplos de salidas guardadas en `yolov5/runs_academic/inferencia_actividad1_val/`.\n",
    "\n",
    "Observacion metodologica:\n",
    "- Esta inferencia se realizo sobre una muestra del split de validacion (`inference_samples_val`).\n",
    "- Por rigor experimental, para una evaluacion final de despliegue se recomienda un set externo no visto (dominio distinto o captura propia).\n",
    "\n",
    "Archivos ejemplo:\n",
    "- Casco_12.jpg\n",
    "- Casco_19.jpg\n",
    "- Casco_7.jpg\n",
    "- Chaleco_26.jpg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e6ea36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar ejemplos de prediccion\n",
    "from pathlib import Path\n",
    "from IPython.display import Image, display\n",
    "\n",
    "pred_dir = Path('yolov5/runs_academic/inferencia_actividad1_val')\n",
    "for p in sorted(pred_dir.glob('*.jpg'))[:4]:\n",
    "    print(p.name)\n",
    "    display(Image(filename=str(p), width=650))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36182261",
   "metadata": {},
   "source": [
    "## 6. Conclusiones y continuidad\n",
    "Evaluacion academica honesta:\n",
    "- La entrega esta bien estructurada y cumple trazabilidad de pipeline completo.\n",
    "- El rendimiento es **aceptable** para una primera iteracion, pero aun no sobresaliente en la clase mas critica.\n",
    "- Con la evidencia actual, esta entrega se ubica en un rango estimado de **8.7/10**.\n",
    "\n",
    "Decision tecnica sobre 10 vs 50 epocas:\n",
    "- **Recomendacion: ampliar a 50 epocas (justificado).**\n",
    "- Motivos: no hay overfitting claro, la loss de validacion sigue bajando, y la precision espacial (`mAP@0.5:0.95`) sigue limitada.\n",
    "- Impacto esperado: mejora **moderada** (no milagrosa), especialmente en localizacion y estabilidad de metricas por clase.\n",
    "\n",
    "Plan academico propuesto para la corrida de 50 epocas:\n",
    "1. Entrenar: `python yolov5/train.py --img 640 --batch 8 --epochs 50 --data dataset_final/custom_data.yaml --weights yolov5s.pt --cache --project yolov5/runs_academic --name actividad1_50e --exist-ok`\n",
    "2. Validar en configuracion fija (`batch=16`, semilla fija) y guardar log textual.\n",
    "3. Comparar 10e vs 50e en tabla unica: P, R, mAP50, mAP50-95 global + por clase.\n",
    "4. Actualizar automaticamente notebook y PDF con rutas nuevas (`actividad1_50e`, `val_actividad1_50e`) sin modificar resultados historicos.\n",
    "\n",
    "Criterio de cierre:\n",
    "- Si 50 epocas no mejora al menos la clase critica (`Persona_Sin_Equipo`) y `mAP@0.5:0.95`, la prioridad debe pasar de \"mas epocas\" a \"mas y mejores datos\".\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}