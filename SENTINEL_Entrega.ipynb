{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# SENTINEL HUD: Sistema de Seguridad Industrial con Vision Artificial\n",
                "\n",
                "**Asignatura**: Vision por Computador Avanzada  \n",
                "**Alumno**: Diego Sanchez  \n",
                "**Fecha**: Febrero 2026\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Definicion del Problema\n",
                "\n",
                "La seguridad industrial es un desafio critico en entornos de construccion y manufactura. La falta de uso de Equipos de Proteccion Individual (EPIs) como cascos y chalecos reflectantes es una de las principales causas de accidentes laborales graves.\n",
                "\n",
                "Los metodos tradicionales de supervision humana son propensos a errores, fatiga y falta de cobertura continua. Este proyecto, **SENTINEL HUD**, propone una solucion automatizada basada en Deep Learning (YOLOv5) para detectar en tiempo real el cumplimiento de normativas de seguridad, alertando proactivamente sobre trabajadores en riesgo (**Persona_Sin_EPI**)."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Dataset y Preprocesamiento\n",
                "\n",
                "Para este proyecto, se ha construido un dataset personalizado utilizando tecnicas de *scraping* automatizado (`dataset_builder.py`) para recopilar imagenes de entornos industriales reales.\n",
                "\n",
                "**Clases del Dataset:**\n",
                "1. `Casco` (Helmet)\n",
                "2. `Chaleco` (Vest)\n",
                "3. `Persona_Sin_EPI` (No PPE - Clase Critica)\n",
                "4. `Peligro` (Danger Signs)\n",
                "\n",
                "A continuacion, descomprimimos el paquete de entrega generado:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "if os.path.exists('dataset_entrega.zip'):\n",
                "    !unzip -q -o dataset_entrega.zip -d dataset_entrega\n",
                "    print(\"[INFO] Dataset de entrega descomprimido.\")\n",
                "else:\n",
                "    print(\"[WARN] Asegurate de subir 'dataset_entrega.zip' al entorno.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Entrenamiento del Modelo (YOLOv5)\n",
                "\n",
                "Utilizamos la arquitectura **YOLOv5s** (Small) por su eficiencia en inferencia de tiempo real, crucial para despliegue en Edge Devices.\n",
                "\n",
                "**Configuracion:**\n",
                "- **Batch Size**: 16\n",
                "- **Epochs**: 50 (Suficiente para convergencia demostrativa)\n",
                "- **Img Size**: 640px\n",
                "- **Weights**: Pre-entrenados en COCO (Transfer Learning)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Instalacion de dependencias YOLOv5\n",
                "if not os.path.exists('yolov5'):\n",
                "    !git clone https://github.com/ultralytics/yolov5\n",
                "    %cd yolov5\n",
                "    %pip install -qr requirements.txt\n",
                "else:\n",
                "    %cd yolov5\n",
                "    \n",
                "import torch\n",
                "from IPython.display import Image, display\n",
                "print(f\"Setup completo. Torch: {torch.__version__}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Comando de Entrenamiento\n",
                "!python train.py --img 640 --batch 16 --epochs 50 --data ../dataset_entrega/custom_data.yaml --weights yolov5s.pt --name sentinel_run --cache"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Analisis de Resultados\n",
                "\n",
                "El entrenamiento genera metricas clave para evaluar el desempeno del modelo:\n",
                "- **Box Loss**: Error en la localizacion de objetos.\n",
                "- **Objectness Loss**: Error en la deteccion de presencia de objetos.\n",
                "- **mAP (Mean Average Precision)**: Metrica estandar de calidad en deteccion.\n",
                "\n",
                "A continuacion, visualizamos el rendimiento del modelo entrenado:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualizacion de Metricas y Matriz de Confusion\n",
                "import glob\n",
                "\n",
                "# Buscar carpeta mas reciente para evitar errores de ruta\n",
                "folders = glob.glob('runs/train/sentinel_run*')\n",
                "if folders:\n",
                "    latest_run = max(folders, key=os.path.getctime)\n",
                "    print(f\"Visualizando resultados de: {latest_run}\")\n",
                "    \n",
                "    results_img = os.path.join(latest_run, 'results.png')\n",
                "    confusion_img = os.path.join(latest_run, 'confusion_matrix.png')\n",
                "    \n",
                "    if os.path.exists(results_img):\n",
                "        display(Image(filename=results_img, width=800))\n",
                "    if os.path.exists(confusion_img):\n",
                "        display(Image(filename=confusion_img, width=800))\n",
                "else:\n",
                "    print(\"Resultados no encontrados. Verifica la ejecucion del entrenamiento.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Inferencia y Despliegue\n",
                "\n",
                "Para superar los requisitos minimos del curso, SENTINEL HUD no se ha quedado en un notebook. El modelo entrenado (`best.pt`) ha sido desplegado en una **arquitectura de microservicios** utilizando:\n",
                "\n",
                "1.  **DockerContainer**: Para aislar el entorno y asegurar reproducibilidad.\n",
                "2.  **WebRTC**: Para permitir streaming de video de baja latencia desde el navegador hacia el contenedor.\n",
                "3.  **Streamlit con CSS Personalizado**: Para una interfaz de usuario \"Industrial Cyberpunk\".\n",
                "\n",
                "### Captura de Pantalla del Dashboard en Funcionamiento:\n",
                "\n",
                "[INSERTAR CAPTURA DE PANTALLA DEL DASHBOARD AQUI]\n",
                "\n",
                "> *La interfaz muestra el HUD superpuesto en tiempo real, con alertas rojas activas al detectar operarios sin equipo de proteccion.*"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}